

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="Description" content="scikit-optimize: machine learning in Python">

  
  <title>skopt.acquisition &mdash; scikit-optimize 0.9.dev0 documentation</title>
  
  <link rel="canonical" href="https://scikit-optimize.github.io/_modules/skopt/acquisition.html" />

  
  <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
<script src="../../_static/jquery.js"></script> 
</head>
<body>
<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../../index.html">
        <img
          class="sk-brand-img"
          src="../../_static/logo.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../install.html">Install</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../user_guide.html">User Guide</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../modules/classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../auto_examples/index.html">Examples</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../getting_started.html">Getting Started</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../development.html">Development</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-optimize/scikit-optimize">GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-optimize.github.io/dev/versions.html">Other Versions</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../../getting_started.html">Getting Started</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../development.html">Development</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-optimize/scikit-optimize">GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-optimize.github.io/dev/versions.html">Other Versions</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="sk-sidebar-toc-logo">
          <a href="../../index.html">
            <img
              class="sk-brand-img"
              src="../../_static/logo.png"
              alt="logo"/>
          </a>
        </div>
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="#" role="button" class="btn sk-btn-rellink py-1 disabled"">Prev</a><a href="../index.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="Module code">Up</a>
            <a href="#" role="button" class="btn sk-btn-rellink py-1 disabled"">Next</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-optimize 0.9.dev0</strong><br/>
            <a href="https://scikit-optimize.github.io/dev/versions.html">Other versions</a>
          </p>
        </div>
          <div class="sk-sidebar-toc">
            
          </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <h1>Source code for skopt.acquisition</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>


<div class="viewcode-block" id="gaussian_acquisition_1D"><a class="viewcode-back" href="../../modules/generated/skopt.acquisition.gaussian_acquisition_1D.html#skopt.acquisition.gaussian_acquisition_1D">[docs]</a><span class="k">def</span> <span class="nf">gaussian_acquisition_1D</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">y_opt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">acq_func</span><span class="o">=</span><span class="s2">&quot;LCB&quot;</span><span class="p">,</span>
                            <span class="n">acq_func_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A wrapper around the acquisition function that is called by fmin_l_bfgs_b.</span>

<span class="sd">    This is because lbfgs allows only 1-D input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_gaussian_acquisition</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                                 <span class="n">model</span><span class="p">,</span> <span class="n">y_opt</span><span class="p">,</span> <span class="n">acq_func</span><span class="o">=</span><span class="n">acq_func</span><span class="p">,</span>
                                 <span class="n">acq_func_kwargs</span><span class="o">=</span><span class="n">acq_func_kwargs</span><span class="p">,</span>
                                 <span class="n">return_grad</span><span class="o">=</span><span class="n">return_grad</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_gaussian_acquisition</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">y_opt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">acq_func</span><span class="o">=</span><span class="s2">&quot;LCB&quot;</span><span class="p">,</span>
                          <span class="n">return_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">acq_func_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Wrapper so that the output of this function can be</span>
<span class="sd">    directly passed to a minimizer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Check inputs</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X is </span><span class="si">{}</span><span class="s2">-dimensional, however,&quot;</span>
                         <span class="s2">&quot; it must be 2-dimensional.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">ndim</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">acq_func_kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">acq_func_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">xi</span> <span class="o">=</span> <span class="n">acq_func_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;xi&quot;</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
    <span class="n">kappa</span> <span class="o">=</span> <span class="n">acq_func_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;kappa&quot;</span><span class="p">,</span> <span class="mf">1.96</span><span class="p">)</span>

    <span class="c1"># Evaluate acquisition function</span>
    <span class="n">per_second</span> <span class="o">=</span> <span class="n">acq_func</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;ps&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">per_second</span><span class="p">:</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">time_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">estimators_</span>

    <span class="k">if</span> <span class="n">acq_func</span> <span class="o">==</span> <span class="s2">&quot;LCB&quot;</span><span class="p">:</span>
        <span class="n">func_and_grad</span> <span class="o">=</span> <span class="n">gaussian_lcb</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">kappa</span><span class="p">,</span> <span class="n">return_grad</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">return_grad</span><span class="p">:</span>
            <span class="n">acq_vals</span><span class="p">,</span> <span class="n">acq_grad</span> <span class="o">=</span> <span class="n">func_and_grad</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">acq_vals</span> <span class="o">=</span> <span class="n">func_and_grad</span>

    <span class="k">elif</span> <span class="n">acq_func</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;EI&quot;</span><span class="p">,</span> <span class="s2">&quot;PI&quot;</span><span class="p">,</span> <span class="s2">&quot;EIps&quot;</span><span class="p">,</span> <span class="s2">&quot;PIps&quot;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">acq_func</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;EI&quot;</span><span class="p">,</span> <span class="s2">&quot;EIps&quot;</span><span class="p">]:</span>
            <span class="n">func_and_grad</span> <span class="o">=</span> <span class="n">gaussian_ei</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">y_opt</span><span class="p">,</span> <span class="n">xi</span><span class="p">,</span> <span class="n">return_grad</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">func_and_grad</span> <span class="o">=</span> <span class="n">gaussian_pi</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">y_opt</span><span class="p">,</span> <span class="n">xi</span><span class="p">,</span> <span class="n">return_grad</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_grad</span><span class="p">:</span>
            <span class="n">acq_vals</span> <span class="o">=</span> <span class="o">-</span><span class="n">func_and_grad</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">acq_grad</span> <span class="o">=</span> <span class="o">-</span><span class="n">func_and_grad</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">acq_vals</span> <span class="o">=</span> <span class="o">-</span><span class="n">func_and_grad</span>

        <span class="k">if</span> <span class="n">acq_func</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;EIps&quot;</span><span class="p">,</span> <span class="s2">&quot;PIps&quot;</span><span class="p">]:</span>

            <span class="k">if</span> <span class="n">return_grad</span><span class="p">:</span>
                <span class="n">mu</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">mu_grad</span><span class="p">,</span> <span class="n">std_grad</span> <span class="o">=</span> <span class="n">time_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                    <span class="n">X</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_mean_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">return_std_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">mu</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="n">time_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="c1"># acq = acq / E(t)</span>
            <span class="n">inv_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">mu</span> <span class="o">+</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">std</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">acq_vals</span> <span class="o">*=</span> <span class="n">inv_t</span>

            <span class="c1"># grad = d(acq_func) * inv_t + (acq_vals *d(inv_t))</span>
            <span class="c1"># inv_t = exp(g)</span>
            <span class="c1"># d(inv_t) = inv_t * grad(g)</span>
            <span class="c1"># d(inv_t) = inv_t * (-mu_grad + std * std_grad)</span>
            <span class="k">if</span> <span class="n">return_grad</span><span class="p">:</span>
                <span class="n">acq_grad</span> <span class="o">*=</span> <span class="n">inv_t</span>
                <span class="n">acq_grad</span> <span class="o">+=</span> <span class="n">acq_vals</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">mu_grad</span> <span class="o">+</span> <span class="n">std</span><span class="o">*</span><span class="n">std_grad</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Acquisition function not implemented.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">return_grad</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">acq_vals</span><span class="p">,</span> <span class="n">acq_grad</span>
    <span class="k">return</span> <span class="n">acq_vals</span>


<div class="viewcode-block" id="gaussian_lcb"><a class="viewcode-back" href="../../modules/generated/skopt.acquisition.gaussian_lcb.html#skopt.acquisition.gaussian_lcb">[docs]</a><span class="k">def</span> <span class="nf">gaussian_lcb</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">kappa</span><span class="o">=</span><span class="mf">1.96</span><span class="p">,</span> <span class="n">return_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Use the lower confidence bound to estimate the acquisition</span>
<span class="sd">    values.</span>

<span class="sd">    The trade-off between exploitation and exploration is left to</span>
<span class="sd">    be controlled by the user through the parameter ``kappa``.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape (n_samples, n_features)</span>
<span class="sd">        Values where the acquisition function should be computed.</span>

<span class="sd">    model : sklearn estimator that implements predict with ``return_std``</span>
<span class="sd">        The fit estimator that approximates the function through the</span>
<span class="sd">        method ``predict``.</span>
<span class="sd">        It should have a ``return_std`` parameter that returns the standard</span>
<span class="sd">        deviation.</span>

<span class="sd">    kappa : float, default 1.96 or &#39;inf&#39;</span>
<span class="sd">        Controls how much of the variance in the predicted values should be</span>
<span class="sd">        taken into account. If set to be very high, then we are favouring</span>
<span class="sd">        exploration over exploitation and vice versa.</span>
<span class="sd">        If set to &#39;inf&#39;, the acquisition function will only use the variance</span>
<span class="sd">        which is useful in a pure exploration setting.</span>
<span class="sd">        Useless if ``method`` is not set to &quot;LCB&quot;.</span>

<span class="sd">    return_grad : boolean, optional</span>
<span class="sd">        Whether or not to return the grad. Implemented only for the case where</span>
<span class="sd">        ``X`` is a single sample.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    values : array-like, shape (X.shape[0],)</span>
<span class="sd">        Acquisition function values computed at X.</span>

<span class="sd">    grad : array-like, shape (n_samples, n_features)</span>
<span class="sd">        Gradient at X.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Compute posterior.</span>
    <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_grad</span><span class="p">:</span>
            <span class="n">mu</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">mu_grad</span><span class="p">,</span> <span class="n">std_grad</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_mean_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">return_std_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">kappa</span> <span class="o">==</span> <span class="s2">&quot;inf&quot;</span><span class="p">:</span>
                <span class="k">return</span> <span class="o">-</span><span class="n">std</span><span class="p">,</span> <span class="o">-</span><span class="n">std_grad</span>
            <span class="k">return</span> <span class="n">mu</span> <span class="o">-</span> <span class="n">kappa</span> <span class="o">*</span> <span class="n">std</span><span class="p">,</span> <span class="n">mu_grad</span> <span class="o">-</span> <span class="n">kappa</span> <span class="o">*</span> <span class="n">std_grad</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">mu</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">kappa</span> <span class="o">==</span> <span class="s2">&quot;inf&quot;</span><span class="p">:</span>
                <span class="k">return</span> <span class="o">-</span><span class="n">std</span>
            <span class="k">return</span> <span class="n">mu</span> <span class="o">-</span> <span class="n">kappa</span> <span class="o">*</span> <span class="n">std</span></div>


<div class="viewcode-block" id="gaussian_pi"><a class="viewcode-back" href="../../modules/generated/skopt.acquisition.gaussian_pi.html#skopt.acquisition.gaussian_pi">[docs]</a><span class="k">def</span> <span class="nf">gaussian_pi</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">y_opt</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">xi</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">return_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Use the probability of improvement to calculate the acquisition values.</span>

<span class="sd">    The conditional probability `P(y=f(x) | x)` form a gaussian with a</span>
<span class="sd">    certain mean and standard deviation approximated by the model.</span>

<span class="sd">    The PI condition is derived by computing ``E[u(f(x))]``</span>
<span class="sd">    where ``u(f(x)) = 1``, if ``f(x) &lt; y_opt`` and ``u(f(x)) = 0``,</span>
<span class="sd">    if``f(x) &gt; y_opt``.</span>

<span class="sd">    This means that the PI condition does not care about how &quot;better&quot; the</span>
<span class="sd">    predictions are than the previous values, since it gives an equal reward</span>
<span class="sd">    to all of them.</span>

<span class="sd">    Note that the value returned by this function should be maximized to</span>
<span class="sd">    obtain the ``X`` with maximum improvement.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape=(n_samples, n_features)</span>
<span class="sd">        Values where the acquisition function should be computed.</span>

<span class="sd">    model : sklearn estimator that implements predict with ``return_std``</span>
<span class="sd">        The fit estimator that approximates the function through the</span>
<span class="sd">        method ``predict``.</span>
<span class="sd">        It should have a ``return_std`` parameter that returns the standard</span>
<span class="sd">        deviation.</span>

<span class="sd">    y_opt : float, default 0</span>
<span class="sd">        Previous minimum value which we would like to improve upon.</span>

<span class="sd">    xi : float, default=0.01</span>
<span class="sd">        Controls how much improvement one wants over the previous best</span>
<span class="sd">        values. Useful only when ``method`` is set to &quot;EI&quot;</span>

<span class="sd">    return_grad : boolean, optional</span>
<span class="sd">        Whether or not to return the grad. Implemented only for the case where</span>
<span class="sd">        ``X`` is a single sample.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    values : [array-like, shape=(X.shape[0],)</span>
<span class="sd">        Acquisition function values computed at X.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_grad</span><span class="p">:</span>
            <span class="n">mu</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">mu_grad</span><span class="p">,</span> <span class="n">std_grad</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_mean_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">return_std_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mu</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># check dimensionality of mu, std so we can divide them below</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">mu</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">std</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;mu and std are </span><span class="si">{}</span><span class="s2">-dimensional and </span><span class="si">{}</span><span class="s2">-dimensional, &quot;</span>
                         <span class="s2">&quot;however both must be 1-dimensional. Did you train &quot;</span>
                         <span class="s2">&quot;your model with an (N, 1) vector instead of an &quot;</span>
                         <span class="s2">&quot;(N,) vector?&quot;</span>
                         <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mu</span><span class="o">.</span><span class="n">ndim</span><span class="p">,</span> <span class="n">std</span><span class="o">.</span><span class="n">ndim</span><span class="p">))</span>

    <span class="n">values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">std</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="n">improve</span> <span class="o">=</span> <span class="n">y_opt</span> <span class="o">-</span> <span class="n">xi</span> <span class="o">-</span> <span class="n">mu</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
    <span class="n">scaled</span> <span class="o">=</span> <span class="n">improve</span> <span class="o">/</span> <span class="n">std</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
    <span class="n">values</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">scaled</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">return_grad</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">values</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">std_grad</span><span class="p">)</span>

        <span class="c1"># Substitute (y_opt - xi - mu) / sigma = t and apply chain rule.</span>
        <span class="c1"># improve_grad is the gradient of t wrt x.</span>
        <span class="n">improve_grad</span> <span class="o">=</span> <span class="o">-</span><span class="n">mu_grad</span> <span class="o">*</span> <span class="n">std</span> <span class="o">-</span> <span class="n">std_grad</span> <span class="o">*</span> <span class="n">improve</span>
        <span class="n">improve_grad</span> <span class="o">/=</span> <span class="n">std</span><span class="o">**</span><span class="mi">2</span>

        <span class="k">return</span> <span class="n">values</span><span class="p">,</span> <span class="n">improve_grad</span> <span class="o">*</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">scaled</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">values</span></div>


<div class="viewcode-block" id="gaussian_ei"><a class="viewcode-back" href="../../modules/generated/skopt.acquisition.gaussian_ei.html#skopt.acquisition.gaussian_ei">[docs]</a><span class="k">def</span> <span class="nf">gaussian_ei</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">y_opt</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">xi</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">return_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Use the expected improvement to calculate the acquisition values.</span>

<span class="sd">    The conditional probability `P(y=f(x) | x)` form a gaussian with a certain</span>
<span class="sd">    mean and standard deviation approximated by the model.</span>

<span class="sd">    The EI condition is derived by computing ``E[u(f(x))]``</span>
<span class="sd">    where ``u(f(x)) = 0``, if ``f(x) &gt; y_opt`` and ``u(f(x)) = y_opt - f(x)``,</span>
<span class="sd">    if``f(x) &lt; y_opt``.</span>

<span class="sd">    This solves one of the issues of the PI condition by giving a reward</span>
<span class="sd">    proportional to the amount of improvement got.</span>

<span class="sd">    Note that the value returned by this function should be maximized to</span>
<span class="sd">    obtain the ``X`` with maximum improvement.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : array-like, shape=(n_samples, n_features)</span>
<span class="sd">        Values where the acquisition function should be computed.</span>

<span class="sd">    model : sklearn estimator that implements predict with ``return_std``</span>
<span class="sd">        The fit estimator that approximates the function through the</span>
<span class="sd">        method ``predict``.</span>
<span class="sd">        It should have a ``return_std`` parameter that returns the standard</span>
<span class="sd">        deviation.</span>

<span class="sd">    y_opt : float, default 0</span>
<span class="sd">        Previous minimum value which we would like to improve upon.</span>

<span class="sd">    xi : float, default=0.01</span>
<span class="sd">        Controls how much improvement one wants over the previous best</span>
<span class="sd">        values. Useful only when ``method`` is set to &quot;EI&quot;</span>

<span class="sd">    return_grad : boolean, optional</span>
<span class="sd">        Whether or not to return the grad. Implemented only for the case where</span>
<span class="sd">        ``X`` is a single sample.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    values : array-like, shape=(X.shape[0],)</span>
<span class="sd">        Acquisition function values computed at X.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_grad</span><span class="p">:</span>
            <span class="n">mu</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">mu_grad</span><span class="p">,</span> <span class="n">std_grad</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_mean_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">return_std_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">mu</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># check dimensionality of mu, std so we can divide them below</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">mu</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">std</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;mu and std are </span><span class="si">{}</span><span class="s2">-dimensional and </span><span class="si">{}</span><span class="s2">-dimensional, &quot;</span>
                         <span class="s2">&quot;however both must be 1-dimensional. Did you train &quot;</span>
                         <span class="s2">&quot;your model with an (N, 1) vector instead of an &quot;</span>
                         <span class="s2">&quot;(N,) vector?&quot;</span>
                         <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mu</span><span class="o">.</span><span class="n">ndim</span><span class="p">,</span> <span class="n">std</span><span class="o">.</span><span class="n">ndim</span><span class="p">))</span>

    <span class="n">values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">std</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="n">improve</span> <span class="o">=</span> <span class="n">y_opt</span> <span class="o">-</span> <span class="n">xi</span> <span class="o">-</span> <span class="n">mu</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
    <span class="n">scaled</span> <span class="o">=</span> <span class="n">improve</span> <span class="o">/</span> <span class="n">std</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
    <span class="n">cdf</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">scaled</span><span class="p">)</span>
    <span class="n">pdf</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">scaled</span><span class="p">)</span>
    <span class="n">exploit</span> <span class="o">=</span> <span class="n">improve</span> <span class="o">*</span> <span class="n">cdf</span>
    <span class="n">explore</span> <span class="o">=</span> <span class="n">std</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">*</span> <span class="n">pdf</span>
    <span class="n">values</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">exploit</span> <span class="o">+</span> <span class="n">explore</span>

    <span class="k">if</span> <span class="n">return_grad</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">mask</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">values</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">std_grad</span><span class="p">)</span>

        <span class="c1"># Substitute (y_opt - xi - mu) / sigma = t and apply chain rule.</span>
        <span class="c1"># improve_grad is the gradient of t wrt x.</span>
        <span class="n">improve_grad</span> <span class="o">=</span> <span class="o">-</span><span class="n">mu_grad</span> <span class="o">*</span> <span class="n">std</span> <span class="o">-</span> <span class="n">std_grad</span> <span class="o">*</span> <span class="n">improve</span>
        <span class="n">improve_grad</span> <span class="o">/=</span> <span class="n">std</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">cdf_grad</span> <span class="o">=</span> <span class="n">improve_grad</span> <span class="o">*</span> <span class="n">pdf</span>
        <span class="n">pdf_grad</span> <span class="o">=</span> <span class="o">-</span><span class="n">improve</span> <span class="o">*</span> <span class="n">cdf_grad</span>
        <span class="n">exploit_grad</span> <span class="o">=</span> <span class="o">-</span><span class="n">mu_grad</span> <span class="o">*</span> <span class="n">cdf</span> <span class="o">-</span> <span class="n">pdf_grad</span>
        <span class="n">explore_grad</span> <span class="o">=</span> <span class="n">std_grad</span> <span class="o">*</span> <span class="n">pdf</span> <span class="o">+</span> <span class="n">pdf_grad</span>

        <span class="n">grad</span> <span class="o">=</span> <span class="n">exploit_grad</span> <span class="o">+</span> <span class="n">explore_grad</span>
        <span class="k">return</span> <span class="n">values</span><span class="p">,</span> <span class="n">grad</span>

    <span class="k">return</span> <span class="n">values</span></div>
</pre></div>

      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2017 - 2020, scikit-optimize contributors (BSD License).
      </footer>
    </div>
  </div>
</div>
<script src="../../_static/js/vendor/bootstrap.min.js"></script>


<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code sampler to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high performance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
    <script src="https://scikit-optimize.github.io/versionwarning.js"></script>
</body>
</html>