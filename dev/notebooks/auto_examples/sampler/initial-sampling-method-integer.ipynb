{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Comparing initial sampling methods on integer space\n\nHolger Nahrstaedt 2020 Sigurd Carlsen October 2019\n\n.. currentmodule:: skopt\n\nWhen doing baysian optimization we often want to reserve some of the\nearly part of the optimization to pure exploration. By default the\noptimizer suggests purely random samples for the first n_initial_points\n(10 by default). The downside to this is that there is no guarantee that\nthese samples are spread out evenly across all the dimensions.\n\nSampling methods as Latin hypercube, Sobol', Halton and Hammersly\ntake advantage of the fact that we know beforehand how many random\npoints we want to sample. Then these points can be \"spread out\" in\nsuch a way that each dimension is explored.\n\nSee also the example on a real space\n`sphx_glr_auto_examples_initial_sampling_method.py`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)\nimport numpy as np\nnp.random.seed(1234)\nimport matplotlib.pyplot as plt\nfrom skopt.space import Space\nfrom skopt.sampler import Sobol\nfrom skopt.sampler import Lhs\nfrom skopt.sampler import Halton\nfrom skopt.sampler import Hammersly\nfrom skopt.sampler import Grid\nfrom scipy.spatial.distance import pdist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_searchspace(x, title):\n    fig, ax = plt.subplots()\n    plt.plot(np.array(x)[:, 0], np.array(x)[:, 1], 'bo', label='samples')\n    plt.plot(np.array(x)[:, 0], np.array(x)[:, 1], 'bs', markersize=40, alpha=0.5)\n    # ax.legend(loc=\"best\", numpoints=1)\n    ax.set_xlabel(\"X1\")\n    ax.set_xlim([0, 5])\n    ax.set_ylabel(\"X2\")\n    ax.set_ylim([0, 5])\n    plt.title(title)\n    ax.grid(True)\n\n\nn_samples = 10\nspace = Space([(0, 5), (0, 5)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random sampling\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = space.rvs(n_samples)\nplot_searchspace(x, \"Random samples\")\npdist_data = []\nx_label = []\nprint(\"empty fields: %d\" % (36 - np.size(np.unique(x, axis=0), 0)))\npdist_data.append(pdist(x).flatten())\nx_label.append(\"random\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sobol'\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sobol = Sobol()\nx = sobol.generate(space.dimensions, n_samples)\nplot_searchspace(x, \"Sobol'\")\nprint(\"empty fields: %d\" % (36 - np.size(np.unique(x, axis=0), 0)))\npdist_data.append(pdist(x).flatten())\nx_label.append(\"sobol'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classic latin hypercube sampling\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lhs = Lhs(lhs_type=\"classic\", criterion=None)\nx = lhs.generate(space.dimensions, n_samples)\nplot_searchspace(x, 'classic LHS')\nprint(\"empty fields: %d\" % (36 - np.size(np.unique(x, axis=0), 0)))\npdist_data.append(pdist(x).flatten())\nx_label.append(\"lhs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Centered latin hypercube sampling\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lhs = Lhs(lhs_type=\"centered\", criterion=None)\nx = lhs.generate(space.dimensions, n_samples)\nplot_searchspace(x, 'centered LHS')\nprint(\"empty fields: %d\" % (36 - np.size(np.unique(x, axis=0), 0)))\npdist_data.append(pdist(x).flatten())\nx_label.append(\"center\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Maximin optimized hypercube sampling\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lhs = Lhs(criterion=\"maximin\", iterations=10000)\nx = lhs.generate(space.dimensions, n_samples)\nplot_searchspace(x, 'maximin LHS')\nprint(\"empty fields: %d\" % (36 - np.size(np.unique(x, axis=0), 0)))\npdist_data.append(pdist(x).flatten())\nx_label.append(\"maximin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Correlation optimized hypercube sampling\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lhs = Lhs(criterion=\"correlation\", iterations=10000)\nx = lhs.generate(space.dimensions, n_samples)\nplot_searchspace(x, 'correlation LHS')\nprint(\"empty fields: %d\" % (36 - np.size(np.unique(x, axis=0), 0)))\npdist_data.append(pdist(x).flatten())\nx_label.append(\"corr\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ratio optimized hypercube sampling\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lhs = Lhs(criterion=\"ratio\", iterations=10000)\nx = lhs.generate(space.dimensions, n_samples)\nplot_searchspace(x, 'ratio LHS')\nprint(\"empty fields: %d\" % (36 - np.size(np.unique(x, axis=0), 0)))\npdist_data.append(pdist(x).flatten())\nx_label.append(\"ratio\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Halton sampling\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "halton = Halton()\nx = halton.generate(space.dimensions, n_samples)\nplot_searchspace(x, 'Halton')\nprint(\"empty fields: %d\" % (36 - np.size(np.unique(x, axis=0), 0)))\npdist_data.append(pdist(x).flatten())\nx_label.append(\"halton\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hammersly sampling\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hammersly = Hammersly()\nx = hammersly.generate(space.dimensions, n_samples)\nplot_searchspace(x, 'Hammersly')\nprint(\"empty fields: %d\" % (36 - np.size(np.unique(x, axis=0), 0)))\npdist_data.append(pdist(x).flatten())\nx_label.append(\"hammersly\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid sampling\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grid = Grid(border=\"include\", use_full_layout=False)\nx = grid.generate(space.dimensions, n_samples)\nplot_searchspace(x, 'Grid')\nprint(\"empty fields: %d\" % (36 - np.size(np.unique(x, axis=0), 0)))\npdist_data.append(pdist(x).flatten())\nx_label.append(\"grid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pdist boxplot of all methods\n\nThis boxplot shows the distance between all generated points using\nEuclidian distance. The higher the value, the better the sampling method.\nIt can be seen that random has the worst performance\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nax.boxplot(pdist_data)\nplt.grid(True)\nplt.ylabel(\"pdist\")\n_ = ax.set_ylim(0, 6)\n_ = ax.set_xticklabels(x_label, rotation=45, fontsize=8)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}