{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Interruptible optimization runs with checkpoints\n\nChristian Schell, Mai 2018\nReformatted by Holger Nahrstaedt 2020\n\n.. currentmodule:: skopt\n\n## Problem statement\n\nOptimization runs can take a very long time and even run for multiple days.\nIf for some reason the process has to be interrupted results are irreversibly\nlost, and the routine has to start over from the beginning.\n\nWith the help of the :class:`callbacks.CheckpointSaver` callback the optimizer's current state\ncan be saved after each iteration, allowing to restart from that point at any\ntime.\n\nThis is useful, for example,\n\n* if you don't know how long the process will take and cannot hog computational resources forever\n* if there might be system failures due to shaky infrastructure (or colleagues...)\n* if you want to adjust some parameters and continue with the already obtained results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)\nimport sys\nimport numpy as np\nnp.random.seed(777)\nimport os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simple example\n\nWe will use pretty much the same optimization problem as in the\n`sphx_glr_auto_examples_bayesian-optimization.py`\nnotebook. Additionally we will instantiate the :class:`callbacks.CheckpointSaver`\nand pass it to the minimizer:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skopt import gp_minimize\nfrom skopt import callbacks\nfrom skopt.callbacks import CheckpointSaver\n\nnoise_level = 0.1\n\n\ndef obj_fun(x, noise_level=noise_level):\n    return np.sin(5 * x[0]) * (1 - np.tanh(x[0] ** 2)) + np.random.randn() \\\n        * noise_level\n\ncheckpoint_saver = CheckpointSaver(\"./checkpoint.pkl\", compress=9) # keyword arguments will be passed to `skopt.dump`\n\ngp_minimize(obj_fun,            # the function to minimize\n            [(-20.0, 20.0)],    # the bounds on each dimension of x\n            x0=[-20.],          # the starting point\n            acq_func=\"LCB\",     # the acquisition function (optional)\n            n_calls=10,         # number of evaluations of f including at x0\n            n_random_starts=3,  # the number of random initial points\n            callback=[checkpoint_saver],\n            # a list of callbacks including the checkpoint saver\n            random_state=777)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's assume this did not finish at once but took some long time: you\nstarted this on Friday night, went out for the weekend and now, Monday\nmorning, you're eager to see the results. However, instead of the\nnotebook server you only see a blank page and your colleague Garry\ntells you that he had had an update scheduled for Sunday noon \u2013 who\ndoesn't like updates?\n\n:class:`gp_minimize` did not finish, and there is no `res` variable with the\nactual results!\n\n## Restoring the last checkpoint\n\nLuckily we employed the :class:`callbacks.CheckpointSaver` and can now restore the latest\nresult with :class:`skopt.load`\n(see `sphx_glr_auto_examples_store-and-load-results.py` for more\ninformation on that)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skopt import load\n\nres = load('./checkpoint.pkl')\n\nres.fun"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Continue the search\n\nThe previous results can then be used to continue the optimization process:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x0 = res.x_iters\ny0 = res.func_vals\n\ngp_minimize(obj_fun,            # the function to minimize\n            [(-20.0, 20.0)],    # the bounds on each dimension of x\n            x0=x0,              # already examined values for x\n            y0=y0,              # observed values for x0\n            acq_func=\"LCB\",     # the acquisition function (optional)\n            n_calls=10,         # number of evaluations of f including at x0\n            n_random_starts=3,  # the number of random initialization points\n            callback=[checkpoint_saver],\n            random_state=777)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Possible problems\n\n* **changes in search space:** You can use this technique to interrupt\n  the search, tune the search space and continue the optimization. Note\n  that the optimizers will complain if `x0` contains parameter values not\n  covered by the dimension definitions, so in many cases shrinking the\n  search space will not work without deleting the offending runs from\n  `x0` and `y0`.\n* see `sphx_glr_auto_examples_store-and-load-results.py`\n\nfor more information on how the results get saved and possible caveats\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}