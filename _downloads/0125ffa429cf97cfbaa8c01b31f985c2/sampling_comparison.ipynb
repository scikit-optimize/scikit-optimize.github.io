{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Comparing initial point generation methods\n\n\nHolger Nahrstaedt 2020\n\n.. currentmodule:: skopt\n\nBayesian optimization or sequential model-based optimization uses a surrogate\nmodel to model the expensive to evaluate function `func`. There are several\nchoices for what kind of surrogate model to use. This notebook compares the\nperformance of:\n\n* Halton sequence,\n* Hammersly sequence,\n* Sobol sequence and\n* Latin hypercube sampling\n\nas initial points. The purely random point generation is used as\na baseline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)\nimport numpy as np\nnp.random.seed(123)\nimport matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Toy model\n=========\n\nWe will use the :class:`benchmarks.hart6` function as toy model for the expensive function.\nIn a real world application this function would be unknown and expensive\nto evaluate.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skopt.benchmarks import hart6 as hart6_\n# redefined `hart6` to allow adding arbitrary \"noise\" dimensions\ndef hart6(x, noise_level=0.):\n    return hart6_(x[:6]) + noise_level * np.random.randn()\n\nfrom skopt.benchmarks import branin as _branin\n\ndef branin(x, noise_level=0.):\n    return _branin(x) + noise_level * np.random.randn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matplotlib.pyplot import cm\nimport time\nfrom skopt import gp_minimize, forest_minimize, dummy_minimize\n\ndef plot_convergence(result_list, true_minimum=None, yscale=None, title=\"Convergence plot\"):\n\n    ax = plt.gca()\n    ax.set_title(title)\n    ax.set_xlabel(\"Number of calls $n$\")\n    ax.set_ylabel(r\"$\\min f(x)$ after $n$ calls\")\n    ax.grid()\n    if yscale is not None:\n        ax.set_yscale(yscale)\n    colors = cm.hsv(np.linspace(0.25, 1.0, len(result_list)))\n\n    for results, color in zip(result_list, colors):\n        name, results = results\n        n_calls = len(results[0].x_iters)\n        iterations = range(1, n_calls + 1)\n        mins = [[np.min(r.func_vals[:i]) for i in iterations]\n                for r in results]\n        ax.plot(iterations, np.mean(mins, axis=0), c=color, label=name)\n        #ax.errorbar(iterations, np.mean(mins, axis=0),\n        #             yerr=np.std(mins, axis=0), c=color, label=name)\n    if true_minimum:\n        ax.axhline(true_minimum, linestyle=\"--\",\n                   color=\"r\", lw=1,\n                   label=\"True minimum\")\n    ax.legend(loc=\"best\")\n    return ax\n\n\ndef run(minimizer, initial_point_generator,\n        n_initial_points=10, n_repeats=1):\n    return [minimizer(func, bounds, n_initial_points=n_initial_points,\n                      initial_point_generator=initial_point_generator,\n                      n_calls=n_calls, random_state=n)\n            for n in range(n_repeats)]\n\n\ndef run_measure(initial_point_generator, n_initial_points=10):\n    start = time.time()\n    # n_repeats must set to a much higher value to obtain meaningful results.\n    n_repeats = 1\n    res = run(gp_minimize, initial_point_generator,\n              n_initial_points=n_initial_points, n_repeats=n_repeats)\n    duration = time.time() - start\n    # print(\"%s %s: %.2f s\" % (initial_point_generator,\n    #                          str(init_point_gen_kwargs),\n    #                          duration))\n    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Objective\n=========\n\nThe objective of this example is to find one of these minima in as\nfew iterations as possible. One iteration is defined as one call\nto the :class:`benchmarks.hart6` function.\n\nWe will evaluate each model several times using a different seed for the\nrandom number generator. Then compare the average performance of these\nmodels. This makes the comparison more robust against models that get\n\"lucky\".\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from functools import partial\nexample = \"hart6\"\n\nif example == \"hart6\":\n    func = partial(hart6, noise_level=0.1)\n    bounds = [(0., 1.), ] * 6\n    true_minimum = -3.32237\n    n_calls = 40\n    n_initial_points = 10\n    yscale = None\n    title = \"Convergence plot - hart6\"\nelse:\n    func = partial(branin, noise_level=2.0)\n    bounds = [(-5.0, 10.0), (0.0, 15.0)]\n    true_minimum = 0.397887\n    n_calls = 30\n    n_initial_points = 10\n    yscale=\"log\"\n    title = \"Convergence plot - branin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skopt.utils import cook_initial_point_generator\n\n# Random search\ndummy_res = run_measure(\"random\", n_initial_points)\nlhs = cook_initial_point_generator(\n    \"lhs\", lhs_type=\"classic\", criterion=None)\nlhs_res = run_measure(lhs, n_initial_points)\nlhs2 = cook_initial_point_generator(\"lhs\", criterion=\"maximin\")\nlhs2_res = run_measure(lhs2, n_initial_points)\nsobol = cook_initial_point_generator(\"sobol\", randomize=False,\n                                     min_skip=1, max_skip=100)\nsobol_res = run_measure(sobol, n_initial_points)\nhalton_res = run_measure(\"halton\", n_initial_points)\nhammersly_res = run_measure(\"hammersly\", n_initial_points)\ngrid_res = run_measure(\"grid\", n_initial_points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that this can take a few minutes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot = plot_convergence([(\"random\", dummy_res),\n                        (\"lhs\", lhs_res),\n                        (\"lhs_maximin\", lhs2_res),\n                        (\"sobol\", sobol_res),\n                        (\"halton\", halton_res),\n                        (\"hammersly\", hammersly_res),\n                        (\"grid\", grid_res)],\n                        true_minimum=true_minimum,\n                        yscale=yscale,\n                        title=title)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This plot shows the value of the minimum found (y axis) as a function\nof the number of iterations performed so far (x axis). The dashed red line\nindicates the true value of the minimum of the :class:`benchmarks.hart6`\nfunction.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test with different n_random_starts values\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lhs2 = cook_initial_point_generator(\"lhs\", criterion=\"maximin\")\nlhs2_15_res = run_measure(lhs2, 12)\nlhs2_20_res = run_measure(lhs2, 14)\nlhs2_25_res = run_measure(lhs2, 16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "n_random_starts = 10 produces the best results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot = plot_convergence([(\"random - 10\", dummy_res),\n                        (\"lhs_maximin - 10\", lhs2_res),\n                        (\"lhs_maximin - 12\", lhs2_15_res),\n                        (\"lhs_maximin - 14\", lhs2_20_res),\n                        (\"lhs_maximin - 16\", lhs2_25_res)],\n                        true_minimum=true_minimum,\n                        yscale=yscale,\n                        title=title)\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}